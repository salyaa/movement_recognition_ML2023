{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - ML\n",
    "### Run - Random Forests with sub-samples for the hyper parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of our data and creation of our machine learning entities X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial data contains 27187 of NaN values\n",
      "There is 27187 rows with 100 percents of NaN positional values.\n",
      "Hence all rows can be removed from our data set.\n",
      "Label y extracted!\n",
      "Label y encoded!\n",
      "Matrix X created!\n"
     ]
    }
   ],
   "source": [
    "# Change the file according to where the .parquet files are in your machine\n",
    "\n",
    "file = 'data/All_Relative_Results_Cleaned.parquet'\n",
    "data = pd.read_parquet(file)\n",
    "\n",
    "X, y, y_encoded = clean_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, we want to see if the camera has an impact in the prediction. Hence, we create four sub-matrices of `X` for each camera: Frontal Top (ft), Frontal Low (fl), Side Top (st) and Side Low (sl). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ft, y_encoded_ft, X_fl, y_encoded_fl, X_st, y_encoded_st, X_sl, y_encoded_sl = submatrices_cameras(X, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the 4 sub-matrices are: \n",
      " Frontal top camera: (552645, 103) \n",
      " Frontal low camera: (552641, 103) \n",
      " Side top camera: (547570, 103) \n",
      " Side low camera: (530629, 103)\n"
     ]
    }
   ],
   "source": [
    "print('The shapes of the 4 sub-matrices are: \\n Frontal top camera:', X_ft.shape,\n",
    "        '\\n Frontal low camera:', X_fl.shape,\n",
    "        '\\n Side top camera:', X_st.shape,\n",
    "        '\\n Side low camera:', X_sl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Separation of Train-Test using the first method:\n",
    "\n",
    "The first method consist of removing the time column from `X` and a split of 50% for\n",
    "testing and 50% for training is performed randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start our classification for each matrix and compare our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names_M1 = list(('X_train_M1', 'X_test_M1'))\n",
    "\n",
    "test_labels_M1, accuracy_M1 = train_test_clustering_rf(X, X_names_M1, y_encoded, 'M1', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frontal Top\n",
    "X_names_ft_M1 = list(('X_Frontal_Top_train_M1', 'X_Frontal_Top_test_M1'))\n",
    "test_labels_ft_M1, accuracy_ft_M1 = train_test_clustering_rf(X_ft, X_names_ft_M1, y_encoded_ft, 'M1', True, False)\n",
    "\n",
    "# Frontal Low\n",
    "X_names_fl_M1 = list(('X_Frontal_Low_train_M1', 'X_Frontal_Low_test_M1'))\n",
    "test_labels_fl_M1, accuracy_fl_M1 = train_test_clustering_rf(X_fl, X_names_fl_M1, y_encoded_fl, 'M1', True, False)\n",
    "\n",
    "# Side Top\n",
    "X_names_st_M1 = list(('X_Side_Top_train_M1', 'X_Side_Top_test_M1'))\n",
    "test_labels_st_M1, accuracy_st_M1 = train_test_clustering_rf(X_st, X_names_st_M1, y_encoded_st, 'M1', True, False)\n",
    "\n",
    "# Side Low\n",
    "X_names_sl_M1 = list(('X_Side_Low_train_M1', 'X_Side_Low_test_M1'))\n",
    "test_labels_sl_M1, accuracy_sl_M1 = train_test_clustering_rf(X_sl, X_names_sl_M1, y_encoded_sl, 'M1', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute the average accuracy when looking at the different cameras:\n",
    "accuracy_cameras_M1 = np.array([accuracy_ft_M1, accuracy_fl_M1, accuracy_st_M1, accuracy_sl_M1])\n",
    "avg_accuracy_M1 = accuracy_cameras_M1.mean()\n",
    "print(f'Average accuracy: {100*avg_accuracy_M1}%')\n",
    "# Now, let us compute the difference in accuracy between our two different results:\n",
    "difference_in_accuracy_M1 = (avg_accuracy_M1 - accuracy_M1)\n",
    "print(f'The difference in accuracy is: {difference_in_accuracy_M1*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Separation of Train-Test using the second method:\n",
    "\n",
    "The second method consist of splitting based on participants and we keep the time column, with 12 participants reserved for testing and 13 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names_M2 = list(('X_train_M2', 'X_test_M2'))\n",
    "\n",
    "test_labels_M2, accuracy_M2 = train_test_clustering_rf(X, X_names_M2, y_encoded, 'M2', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frontal Top\n",
    "X_names_ft_M2 = list(('X_Frontal_Top_train_M2', 'X_Frontal_Top_test_M2'))\n",
    "test_labels_ft_M2, accuracy_ft_M2 = train_test_clustering_rf(X_ft, X_names_ft_M2, y_encoded_ft, 'M2', True, False)\n",
    "\n",
    "# Frontal Low\n",
    "X_names_fl_M2 = list(('X_Frontal_Low_train_M2', 'X_Frontal_Low_test_M2'))\n",
    "test_labels_fl_M2, accuracy_fl_M2 = train_test_clustering_rf(X_fl, X_names_fl_M2, y_encoded_fl, 'M2', True, False)\n",
    "\n",
    "# Side Top\n",
    "X_names_st_M2 = list(('X_Side_Top_train_M2', 'X_Side_Top_test_M2'))\n",
    "test_labels_st_M2, accuracy_st_M2 = train_test_clustering_rf(X_st, X_names_st_M2, y_encoded_st, 'M2', True, False)\n",
    "\n",
    "# Side Low\n",
    "X_names_sl_M2 = list(('X_Side_Low_train_M2', 'X_Side_Low_test_M2'))\n",
    "test_labels_sl_M2, accuracy_sl_M2 = train_test_clustering_rf(X_sl, X_names_sl_M2, y_encoded_sl, 'M2', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute the average accuracy when looking at the different cameras:\n",
    "accuracy_cameras_M2 = np.array([accuracy_ft_M2, accuracy_fl_M2, accuracy_st_M2, accuracy_sl_M2])\n",
    "avg_accuracy_M2 = accuracy_cameras_M2.mean()\n",
    "print(f'Average accuracy: {100*avg_accuracy_M2}%')\n",
    "\n",
    "# Now, let us compute the difference in accuracy between our two different results:\n",
    "difference_in_accuracy_M2 = (avg_accuracy_M2 - accuracy_M2)\n",
    "print(f'The difference in accuracy is: {difference_in_accuracy_M2*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Separation of Train-Test using the third method:\n",
    "\n",
    "The third method consist of taking a certain percentage p for the training set of each unique values of the feature ’Camera’, so that training take into consideration each cameras.\n",
    "\n",
    "Remark that for this method, we cannot compare the sub-matrices of each cameras and our whole matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names_M3 = list(('X_train_M3', 'X_test_M3'))\n",
    "\n",
    "test_labels_M3, accuracy_M3 = train_test_clustering_rf(X, X_names_M3, y_encoded, 'M3', True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Separation of Train-Test using the fourth method:\n",
    "\n",
    "The third method consist of taking a certain percentage p for the training set of each unique values of the feature ’Set’, so that training take into consideration each errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names_M4 = list(('X_train_M4', 'X_test_M4'))\n",
    "\n",
    "test_labels_M4, accuracy_M4 = train_test_clustering_rf(X, X_names_M4, y_encoded, 'M4', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frontal Top\n",
    "X_names_ft_M4 = list(('X_Frontal_Top_train_M4', 'X_Frontal_Top_test_M4'))\n",
    "test_labels_ft_M4, accuracy_ft_M4 = train_test_clustering_rf(X_ft, X_names_ft_M4, y_encoded_ft, 'M4', True, False)\n",
    "\n",
    "# Frontal Low\n",
    "X_names_fl_M4 = list(('X_Frontal_Low_train_M4', 'X_Frontal_Low_test_M4'))\n",
    "test_labels_fl_M4, accuracy_fl_M4 = train_test_clustering_rf(X_fl, X_names_fl_M4, y_encoded_fl, 'M4', True, False)\n",
    "\n",
    "# Side Top\n",
    "X_names_st_M4 = list(('X_Side_Top_train_M4', 'X_Side_Top_test_M4'))\n",
    "test_labels_st_M4, accuracy_st_M4 = train_test_clustering_rf(X_st, X_names_st_M4, y_encoded_st, 'M4', True, False)\n",
    "\n",
    "# Side Low\n",
    "X_names_sl_M4 = list(('X_Side_Low_train_M4', 'X_Side_Low_test_M4'))\n",
    "test_labels_sl_M4, accuracy_sl_M4 = train_test_clustering_rf(X_sl, X_names_sl_M4, y_encoded_sl, 'M4', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute the average accuracy when looking at the different cameras:\n",
    "accuracy_cameras_M4 = np.array([accuracy_ft_M4, accuracy_fl_M4, accuracy_st_M4, accuracy_sl_M4])\n",
    "avg_accuracy_M4= accuracy_cameras_M4.mean()\n",
    "print(f'Average accuracy: {100*avg_accuracy_M4}%')\n",
    "\n",
    "# Now, let us compute the difference in accuracy between our two different results:\n",
    "difference_in_accuracy_M4 = (avg_accuracy_M4 - accuracy_M4)\n",
    "print(f'The difference in accuracy is: {difference_in_accuracy_M4*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
